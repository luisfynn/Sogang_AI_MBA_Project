---
title: "ABF_Week6_HW"
author: "taehwan.lee"
date: "2024-02-03"
output: word_document
---
```{r}
# data 불러오기
data <- read.csv("GermanCredit.csv", header = T)
data
```

```{r}
data[,c(1,2,4,5,7,8,10,11,13,15,16,18,20,21)] <- lapply( data[,c(1,2,4,5,7,8,10,11,13,15,16,18,20,21)], as.factor)
data$good.bad <- as.factor(as.numeric(data$good.bad) - 1)
str(data)
```
```{r}
data$amount <- as.factor(ifelse(data$amount <= 2500, '0-2500', ifelse(data$amount <= 5000,'2500-5000','5000+')))
head(data)
```
# 데이터 분리1
```{r}
library(sampling)
n <- nrow(data) #data의 row 수를 n에 넣기기
d <- sort(sample(n, n*0.6)) #전체 행 중에 60%의 행을 랜덤하게 선택하여 d에 넣기
train <- data[d,] # d에 해당하는 data 추출하여 train에 넣기
test <- data[-d,] # d에 해당하지 않는 data 추출하여 test에 넣기
```
# 데이터 분리2
```{r}
set.seed(123457)
#good.bad == "0"인 행을 추출하여 수치형으로 변환 후 good_idx에 넣기
good_idx <- as.numeric(row.names(data[data$good.bad == "0",])) 
#good.bad == "1"인 행을 추출하여 수치형으로 변환 후 bad_idx에 넣기
bad_idx <- as.numeric(row.names(data[data$good.bad == "1",]))
good_n <- length(good_idx)
bad_n <- length(bad_idx)

Train_good_idx <- sample(good_idx, 0.6*good_n) #good_idx 개수 중 60% 랜덤추출하여 Train_good_idx넣기
Test_good_idx <- setdiff(good_idx,Train_good_idx) #good_idx에서 Train_good_idx를 뺀 나머지를 Test_good_idx에 넣기
Train_bad_idx <- sample(bad_idx, 0.6*bad_n)
Test_bad_idx <- setdiff(bad_idx,Train_bad_idx)
#Train_good_idx, Train_bad_idx 합치고 오름차순으로 정렬하여 Train_idx에 넣기
Train_idx <- sort(union(Train_good_idx, Train_bad_idx)) 
train <- data[Train_idx,]
test <- data[-Train_idx,]
```
# 데이터 분리3
```{r}
library(splitstackshape)
set.seed(123457)
#good.bad의 good/bad를 각각 60%씩 균일하게 추출하여 train1에 넣기
train1 <- stratified(data, 'good.bad', 0.6, keep.rownames = TRUE)
#추출된 train1의 rn열을 오름차순으로 정렬 후, data 에서 train1$rn을 제외한 행을 추출하여 test1에 넣기
test1 <- data[-sort(as.numeric(train1$rn)), ]
head(test1)
```

# logistic regression
```{r}
Full_model <- glm(good.bad~., data=train, family=binomial())
step(Full_model, direction="backward")
```



# 참고
```{r}
library(dplyr)
library(MASS)# Cars93 dataframe을 얻기 위함 . 자동차에 관한 27 개 변수 93 개 관측값으로 구성
```

(1) Cars93 데이터프레임에서 %>% (2) 제조생산국 (Origin), 차종 (Type), 실린더개수 (Cylinders) 별로 %>% 
(3) 차 가격 (Price) 과 고속도로 연비 (MPG.highway) 변수에 대하여 결측값은 제외하고 ) 평균
을 구하는데 , %>% (4) 단 , 가격 평균은 10 을 넘거나 또는 고속도로 연비는 25 를 넘는 것만 선택 출력

dataframe %>% group_by() %>% summarise() %>% filter()의 순서

```{r}
Cars93 %>% group_by(Origin, Type, Cylinders) %>%
  summarise(P_m = mean(Price, na.rm = T),
            M_m = mean(MPG.highway, na.rm = T)) %>%
  filter(P_m > 10 | M_m > 25)
```

# 변수별 우량/불량에 대한 분포
```{r}
library(dplyr)
library(ggplot2)
train %>% ggplot(aes(age, fill = good.bad)) + geom_density(alpha = 0.5)
train %>% filter(martial %in% c('1', '2', '4'), existcr %in% c('1', '2')) %>%
  ggplot(aes(age, fill = good.bad)) + geom_density(alpha = 0.5) +
  facet_grid(martial ~ existcr)
```
### 첫 번째 코드 라인
```r
train %>% ggplot(aes(age, fill = good.bad)) + geom_density(alpha = 0.5)
```

- `train %>%`: `dplyr` 패키지의 파이프 연산자 `%>%`를 사용하여 `train` 데이터 프레임을 다음 함수로 전달합니다.
- `ggplot(aes(age, fill = good.bad))`: `ggplot2` 패키지의 `ggplot` 함수를 사용하여 데이터의 시각화를 시작합니다. `aes` 함수는 미적 요소를 정의하는데 사용되며, 여기서는 `age`를 x축에 매핑하고, `good.bad` 변수의 값에 따라 색상을 다르게 하여 밀도 그래프를 채우도록 설정합니다.
- `geom_density(alpha = 0.5)`: 데이터의 밀도를 표시하는 그래프를 추가합니다. `alpha = 0.5`는 그래프의 투명도를 조절하여 겹치는 부분의 구분을 용이하게 합니다.

### 두 번째 코드 라인
```r
train %>% filter(martial %in% c('1', '2', '4'), existcr %in% c('1', '2')) %>%
  ggplot(aes(age, fill = good.bad)) + geom_density(alpha = 0.5) +
  facet_grid(martial ~ existcr)
```

- `train %>% filter(martial %in% c('1', '2', '4'), existcr %in% c('1', '2'))`: `filter` 함수를 사용하여 `train` 데이터 프레임에서 `martial` 변수의 값이 '1', '2', 또는 '4'인 행과, `existcr` 변수의 값이 '1' 또는 '2'인 행만을 선택합니다.
- `ggplot(aes(age, fill = good.bad)) + geom_density(alpha = 0.5)`: 첫 번째 코드 라인과 동일하게 `age` 변수를 기반으로 한 밀도 그래프를 생성하고, `good.bad` 변수의 값에 따라 색상을 구분합니다.
- `facet_grid(martial ~ existcr)`: `facet_grid`를 사용하여 그래프를 `martial` 변수의 값에 따라 행으로, `existcr` 변수의 값에 따라 열로 분할하여 여러 패널로 나누어 시각화합니다. 이는 데이터의 서브그룹 간 비교를 용이하게 합니다.

이 코드들은 데이터의 분포를 시각적으로 탐색하고, 특정 조건을 만족하는 서브그룹 내에서 `age` 변수의 분포가 `good.bad` 변수의 값에 따라 어떻게 다른지 비교하는 데 사용됩니다.


# 최종 모형 설정 및 계수 특징 확인
```{r}
Logistic_Model <-
  glm(
    good.bad ~ checking + duration + history + purpose + amount + savings +
      employed + installp + coapp + other + housing + existcr,
    family = binomial(),
    data = train
  )
summary(Logistic_Model)
```

```{r}
predict(Logistic_Model, type='response', test[1:3,]) #test 맨위 3개 행 선택하여 예측(1, 3, 8행)
# 결과는 확률로 출력됨
```
```{r}
test[1:3, ]$good.bad #맨 위 3개 행의 good/bad는 bad, bad, good임
```
테스트 데이터를 전부 예측하여 test$phat에 저장
```{r}
test$phat <- predict(Logistic_Model, type='response', test)
```

```{r}
library(gridExtra)
F1 <- test %>% ggplot(aes(good.bad, phat, group=good.bad, fill=good.bad))+geom_boxplot()
F2 <- test %>% ggplot(aes(phat, fill=good.bad))+geom_density(alpha=0.5)
grid.arrange(F1,F2, ncol=2)
```
이 코드는 R 언어를 사용하여 데이터 시각화를 수행하는 과정을 나타냅니다. 여기서도 `dplyr`와 `ggplot2` 패키지, 그리고 `gridExtra` 패키지의 기능을 활용합니다. 각 부분의 작업을 설명하겠습니다.

### 첫 번째 그래프 (`F1`)
```r
F1 <- test %>% ggplot(aes(good.bad, phat, group=good.bad, fill=good.bad)) + geom_boxplot()
```
- `test %>%`: `dplyr`의 파이프 연산자를 사용하여 `test` 데이터 프레임을 `ggplot` 함수로 전달합니다.
- `ggplot(aes(good.bad, phat, group=good.bad, fill=good.bad))`: `ggplot` 함수로 박스플롯을 그릴 기본 설정을 합니다. 여기서는 x축에 `good.bad` 변수, y축에 `phat` 변수를 사용합니다. `group=good.bad`와 `fill=good.bad`는 박스플롯의 그룹화와 색상 채우기를 `good.bad` 변수의 값에 따라 다르게 설정합니다.
- `geom_boxplot()`: 박스플롯을 생성하는 명령입니다. 이는 `phat` 값의 분포를 `good.bad` 값에 따라 비교하기 위해 사용됩니다.

### 두 번째 그래프 (`F2`)
```r
F2 <- test %>% ggplot(aes(phat, fill=good.bad)) + geom_density(alpha=0.5)
```
- `ggplot(aes(phat, fill=good.bad))`: 데이터의 밀도 그래프를 그리기 위한 기본 설정을 합니다. 여기서는 `phat` 값을 연속적인 x축 변수로 사용하고, `good.bad` 변수의 값에 따라 색상을 다르게 적용합니다.
- `geom_density(alpha=0.5)`: 데이터의 밀도를 나타내는 그래프를 생성하며, `alpha=0.5`로 투명도를 조정해 겹치는 부분을 더 잘 볼 수 있게 합니다.

### 두 그래프 병렬 배치
```r
grid.arrange(F1, F2, ncol=2)
```
- `grid.arrange(F1, F2, ncol=2)`: `gridExtra` 패키지의 `grid.arrange` 함수를 사용하여 `F1`과 `F2`라는 두 개의 그래프를 나란히 배치합니다. `ncol=2`는 두 그래프를 2열로 배치하라는 의미입니다.

이 코드는 `test` 데이터 세트에서 `good.bad` 변수에 따른 `phat` 값의 분포를 박스플롯과 밀도 그래프로 시각화하여, 이 두 변수 간의 관계를 탐색하는 데 사용됩니다. `F1`은 `good.bad`의 각 값에 대한 `phat`의 분포를 박스플롯으로 보여주고, `F2`는 `phat` 값의 전체적인 밀도 분포를 `good.bad`의 값에 따라 색으로 구분하여 보여줍니다.


# 모형 분석을 통한 승인 또는 거절 이유 확인
```{r}
Terms=predict(Logistic_Model, type='terms',test[1,])
Tmp=abs(Terms) #절대값으로 변경
Tmp
```
```{r}
print(order(Tmp, decreasing = TRUE))#Tmp값(절대값)을 내림차순으로 정렬 후, 해당값의 인덱스 번호를 나열
Terms[,order(Tmp, decreasing = TRUE)][1:5]  #Tmp값(절대값)을 내림차순으로 정렬 후, 해당값의 인덱스 번호로 상위 5개 데이터를 추출
```

```{r}
res=names(Terms[,order(Tmp, decreasing = TRUE)][1:5]) # 열이름 추출
print(res) 
paste(res,collapse="; ",sep="")
```
R의 `paste` 함수는 벡터를 문자열로 변환한 후 연결하는 데 사용됩니다. 'collapse' 및 'sep' 인수는 이러한 문자열이 결합되는 방식을 제어합니다. 제공한 코드 조각에서 다음을 수행합니다.

- `res`는 단일 문자열로 연결하려는 요소의 벡터입니다.
- `collapse="; "`는 `res`의 요소를 단일 문자열로 연결하고 각 요소를 `;로 구분하도록 지정합니다. `(세미콜론 다음에 공백이 옵니다).
- `sep=""`는 요소가 연결될 때 요소를 구분하는 데 사용되는 문자열을 정의하므로 이 맥락에서 다소 중복됩니다. 그러나 'collapse'는 모든 요소를 단일 문자열로 병합하는 데 사용되므로 'sep'의 역할은 'collapse'에 의해 가려집니다. `collapse`가 없으면 `sep`은 `res`의 개별 요소가 결합되는 방식을 정의합니다.


```{r}
test$phat[1]
```
# ROC Curve
```{r}
library(ROCR)
pred=prediction(test$phat, test$good.bad)
perf=performance(pred,"tpr","fpr")
plot(perf,colorize=TRUE, main='ROC Curve: Logistic')
text(0.6,0.3,adj=0,labels="AUROC (Area Under the ROC Curve)")
text(0.6,0.2,adj=0,labels="- ROC Curve 아래면적을 가르킴")
abline(0,1) #절편이 0 기울기가 1인 라인 그리기
performance(pred,"auc")@y.values[[1]] # AUROC
```
# Confusion Matrix 관련 지표
```{r}
library(caret)
library(e1071)
confusionMatrix(data=as.factor(as.numeric(test$phat>0.5)), reference=test$good.bad)
```

# Cost Marix를 고려한 Cut Off 설정
```{r}
t <- data.frame(CutOff=0, Type11=0, Type12=0, Type51=0, Type52=0, Acc=0)
t
```

```{r}
for(i in seq(0.01, 0.99, 0.01)) {
  CM = confusionMatrix(data = as.factor(as.numeric(test$phat > i)),
                       reference = test$good.bad)
  t1 = CM$overall[[1]] # Accuracy
  t2 = CM$table[1, 2] # Predict Good at Bad (Type 1) #good을 bad로 예측
  t3 = CM$table[2, 1] # Predict Bad at Good (Type 2) #bad를 good으로 예측
  tt = data.frame(
    CutOff = i,
    Type11 = 0.5 * t2,
    Type12 = 0.5 * t3,
    Type51 = (5 / 6) * t2,
    Type52 = t3 / 6,
    Acc = t1
  )
  t = rbind(t, tt)
}

head(t)
```

```{r}
tail(t)
```



```{r}
t <- t[-1, ] #CutOff 0인 행 제거
t
```
```{r}
t$Type1 = t$Type11 + t$Type12
t$Type5 = t$Type51 + t$Type52
t[t$Type1 == min(t$Type1), ]
```


```{r}
t[t$Type5==min(t$Type5),]
```

```{r}
plot(t$CutOff,t$Acc, type="l", lwd=2, xlab="Cut Off Values", ylab="Accuracy")
```
```{r}
plot(t$CutOff,t$Type1, type="l", lwd=2, xlab="Cut Off Values", ylab="Cost",main="1:1 Cost Matrix", ylim=c(0,140))
lines(t$CutOff,t$Type11, type="l", lwd=2, col="blue")
lines(t$CutOff,t$Type12,type="l", lwd=2, col="red")
legend("topright", legend = c("Type 1 error","Type 2 error"), lwd=2, pch = 19, col = c("blue","red"))
```

```{r}
plot(t$CutOff,t$Type5, type="l", lwd=2, xlab="Cut Off Values", ylab="Cost",main="5:1 Cost
Matrix", ylim=c(0,140))
lines(t$CutOff,t$Type51, type="l", lwd=2, col="blue")
lines(t$CutOff,t$Type52,type="l", lwd=2, col="red")
legend("topright", legend = c("Type 1 error","Type 2 error"), lwd=2, pch = 19, col = c("blue","red"))
```

# Tree 모델
```{r}
library(rpart)
fit1=rpart(good.bad~., data=train)
fit1
```

```{r}
#결과를 자세하게 보고 싶은 경우
printcp(fit1)
print("============================================")
print("============================================")
summary(fit1)
```
```{r, fig.height=7}
#패키지에서 제공하는 짜증나는 그림
plot(fit1)
text(fit1, use.n=TRUE)
```

```{r, fig.height=6}
# 조금 이쁜 그림
library(rattle)
library(rpart.plot)
library(RColorBrewer) # Color selection
fancyRpartPlot(fit1)
```

```{r, fig.height=6}
#괜찮은 그림
library(rpart.plot)
rpart.plot(
  fit1,
  box.palette = "RdBu",
  shadow.col = "gray",
  cex = 0.8,
  nn = TRUE
)
```

```{r}
#score test data
#logistic regression ROC curve
pred = prediction(test$phat, test$good.bad)
perf = performance(pred, "tpr", "fpr")
performance(pred, "auc")@y.values[[1]]

#tree ROC Curve
test$phat1 = predict(fit1, test)[, 2]
pred1 = prediction(test$phat1, test$good.bad)
perf1 = performance(pred1, "tpr", "fpr")
performance(pred1, "auc")@y.values[[1]]
```

```{r, fig.height=6}
plot(perf,
     col = 'black',
     lwd = 2,
     main = 'ROC Curves')
plot(perf1,
     col = 'red',
     lwd = 2,
     add = TRUE)
legend(
  'bottomright',
  legend = c('Logistic', 'Tree
Model'),
pch = 19,
col = c('black', 'red')
)
```


# RANDOM Forest
```{r}
library(randomForest)
set.seed(123457)
fit2=randomForest(good.bad~., train)
fit2
```


```{r}
varImpPlot(fit2, main="Importance of Variables")
Impor=importance(fit2)
Impor[order(Impor, decreasing=TRUE)[1:5],]
```

```{r}
test$phat2=predict(fit2, type='prob',test)[,2]
pred2=prediction(test$phat2,test$good.bad)
perf2 =performance(pred2,"tpr","fpr")
performance(pred,"auc")@y.values[[1]]  #logistic regression
performance(pred1,"auc")@y.values[[1]] #tree
performance(pred2,"auc")@y.values[[1]] #random forest
```


```{r}
plot(perf, col='black', lwd=2, main='ROC Curves') #logistic regression
plot(perf1,col='red', lwd=2, add=TRUE)            #tree
plot(perf2,col='blue', lwd=2, add=TRUE)           #random forest
legend(
  'bottomright',
  inset = 0.1,
  legend = c('Logistic', 'Tree Model', 'Random
Forest'),
lty = 1,
col = c('black', 'red', 'blue')
)
```

