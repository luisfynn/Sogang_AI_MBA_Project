# -*- coding: utf-8 -*-
"""텍스트마이닝팀프.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ee_Bbjwtj5jny2YpVRURykKVFh4GWnZm
"""

from bs4 import BeautifulSoup
import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

!sudo apt-get install -y fonts-nanum
!sudo fc-cache -fv
!rm ~/.cache/matplotlib -rf

!pip install konlpy
from konlpy.tag import Kkma
tokenizer=Kkma()

from google.colab import drive
drive.mount('/content/drive')

file_path = '/content/drive/MyDrive/Colab Notebooks/Textmining/대통령_취임사.csv'

import pandas as pd

# CSV 파일 읽기
df = pd.read_csv(file_path)

# 특정 열 두 개 선택
selected_df = df[['대통령', '연설내용']] # 실제 열 이름으로 수정 필요

from konlpy.tag import Kkma
kkma = Kkma()


# NaN 값을 제거
selected_df = selected_df.dropna(subset=['연설내용'])

# '연설내용' 열을 문자열로 변환
selected_df['연설내용'] = selected_df['연설내용'].astype(str)

# 특수 문자 제거 (한글과 공백만 남기기)
selected_df['연설내용'] = selected_df['연설내용'].apply(lambda x: re.sub('[^가-힣\s]', '', x))


# '대통령' 열을 기준으로 데이터 그룹화
grouped = selected_df.groupby('대통령')


# 각 대통령별 연설문 토크나이징
tokenized_data = {}
for president, group in grouped:
    tokenized_texts = group['연설내용'].apply(lambda x: kkma.morphs(x))
    tokenized_data[president] = tokenized_texts.tolist()

# 결과 출력
for president, tokens in tokenized_data.items():
    print(f'대통령: {president}')
    for token_list in tokens:
        print(token_list)

# 파일에서 불용어 불러오기
file_path = '/content/drive/MyDrive/Colab Notebooks/Textmining/mystopwords.txt'
with open(file_path, 'r', encoding='utf-8') as f:
    file_stopwords = [line.strip() for line in f.readlines()]

# 기본 불용어
basic_stopwords = [
    '하', '의', '을', '에', '는', '이', '를', '과', '도', '와', '으로', '에서', '위하','대하','시다', '로', '에게', '라', '만', '게','고자', '로서', '으로서', '다', '때', '것', '곳'
]

# 두 불용어 리스트 합치기
stopwords = file_stopwords + basic_stopwords

# 중복된 불용어 제거
stopwords = list(set(stopwords))

from collections import Counter

pos_frequencies = {}

# 대통령별로 토큰과 해당 토큰의 품사를 묶어서 빈도 계산
for president, token_lists in tokenized_data.items():
    token_pos_counts = Counter()

    for tokens in token_lists:
        pos_tagged_tokens = kkma.pos(" ".join(tokens))

        # 길이가 두 글자 이상이며 불용어에 속하지 않는 토큰만 포함
        filtered_tokens = [
            (token, pos) for token, pos in pos_tagged_tokens
            if len(token) >= 2 and token not in stopwords
        ]

        token_pos_counts.update(filtered_tokens)

    sorted_pos_counts = sorted(token_pos_counts.items(), key=lambda x: x[1], reverse=True)
    pos_frequencies[president] = sorted_pos_counts


# 결과 출력
for president, sorted_pos_counts in pos_frequencies.items():
    for (token, pos), freq in sorted_pos_counts:
        print(f'대통령: {president}, 단어: {token}, 품사: {pos}, 빈도: {freq}')

# 결과 출력
for president, sorted_pos_counts in pos_frequencies.items():
    print(f'대통령: {president}')
    for (token, pos), freq in sorted_pos_counts[:20]:  # 상위 20개만 출력
        print(f'단어: {token}, 품사: {pos}, 빈도: {freq}')
    print("-" * 50)  # 구분선

top_nouns_by_president = {}

# 각 대통령별로 'N'으로 시작하는 품사의 토큰만 상위 20개 선택
for president, sorted_pos_counts in pos_frequencies.items():
    top_nouns = [(token, freq) for (token, pos), freq in sorted_pos_counts if pos.startswith('N')]
    top_nouns_by_president[president] = top_nouns

# 결과 출력
for president, top_nouns in top_nouns_by_president.items():
    print(f'대통령: {president}')
    for token, freq in top_nouns:
        print(f'단어: {token}, 빈도: {freq}')
    print('-' * 50)  # 구분선

!pip install wordcloud

from wordcloud import WordCloud
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm


font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
font_name = fm.FontProperties(fname=font_path, size=10).get_name()
plt.rc('font', family=font_name)

for president, top_nouns in top_nouns_by_president.items():
    # 워드클라우드 설정
    wc = WordCloud(
        font_path=font_path,  # 폰트 경로
        background_color='white',  # 배경색 설정
        width=300,
        height=300
    )

    # 워드클라우드 생성
    wordcloud = wc.generate_from_frequencies(dict(top_nouns))

    # 그래프 설정 및 표시
    plt.figure(figsize=(5, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.title(f'대통령: {president}')
    plt.axis('off')
    plt.show()

top_20_nouns_by_president = {}

# 각 대통령별로 'N'으로 시작하는 품사의 토큰만 상위 20개 선택
for president, sorted_pos_counts in pos_frequencies.items():
    top_20_nouns = [(token, freq) for (token, pos), freq in sorted_pos_counts if pos.startswith('N')][:20]
    top_20_nouns_by_president[president] = top_20_nouns

# 결과 출력
for president, top_nouns in top_20_nouns_by_president.items():
    print(f'대통령: {president}')
    for token, freq in top_nouns:
        print(f'단어: {token}, 빈도: {freq}')
    print('-' * 50)  # 구분선

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

import seaborn as sns

path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'
fontprop = fm.FontProperties(fname=path, size=5)
plt.rc('font', family='NanumGothic')


for president, top_nouns in top_20_nouns_by_president.items():
    plt.figure(figsize=(8, 5))  # 그래프 크기 설정

    # 데이터 분리
    words, frequencies = zip(*top_nouns)

    # 그래프 그리기
    sns.barplot(x=list(frequencies), y=list(words))
    plt.title(f"Top 20 Nouns used by {president}")  # 제목 설정
    plt.xlabel('Frequency')  # x축 라벨 설정
    plt.ylabel('Words')      # y축 라벨 설정
    plt.show()